# Task 2 åç«¯å¢å¼ºåŠŸèƒ½è¯´æ˜

## âœ… å·²å®ŒæˆåŠŸèƒ½

### 1. å†å²ä¸Šä¸‹æ–‡æ”¯æŒï¼ˆMemory Contextï¼‰

**ç›®çš„**: è®© AI èƒ½å¤Ÿç†è§£ä¹‹å‰çš„å¯¹è¯ï¼Œåšå‡ºæ›´è¿è´¯ã€æ›´ç¬¦åˆä¸Šä¸‹æ–‡çš„å»ºè®®ã€‚

#### åç«¯ä¿®æ”¹

1. **models/schemas.py** - `ChatRequest` æ¨¡å‹
   ```python
   class ChatRequest(BaseModel):
       user_input: str  # å¯¹æ–¹æœ€æ–°æ¶ˆæ¯
       history: List[dict] = []  # å†å²è®°å½•ï¼ˆæœ€å¤š32æ¡ï¼‰
   ```
   - æ–°å¢ `history` å­—æ®µï¼Œæ ¼å¼: `[{"role": "user", "content": "..."}, ...]`
   - æ·»åŠ éªŒè¯å™¨ï¼šé™åˆ¶æœ€å¤š 32 æ¡å†å²è®°å½•

2. **services/ai_service.py** - `AIService` ç±»
   - æ–°å¢ `_build_context_prompt()` æ–¹æ³•ï¼š
     - æ ¼å¼åŒ–å†å²è®°å½•ä¸ºæ˜“è¯»çš„ä¸Šä¸‹æ–‡
     - å°†å†å²æ’å…¥åˆ° Prompt ä¸­
   - æ›´æ–° `generate_response(user_input, history)`:
     - æ¥æ”¶ `history` å‚æ•°
     - æ—¥å¿—è®°å½•å†å²æ·±åº¦

3. **main.py** - `/api/chat` ç«¯ç‚¹
   - æ›´æ–°æ¥æ”¶ `request.history`
   - ä¼ é€’ç»™ `ai_service.generate_response()`

#### API ä½¿ç”¨ç¤ºä¾‹

```python
import requests

response = requests.post("http://127.0.0.1:8000/api/chat", json={
    "user_input": "ä½ ä¸ºä»€ä¹ˆä¸å›åº”æˆ‘ï¼Ÿ",
    "history": [
        {"role": "user", "content": "æˆ‘å–œæ¬¢ä½ "},
        {"role": "assistant", "content": "è°¢è°¢ä½ çš„å¿ƒæ„ï¼Œä¸è¿‡..."}
    ]
})
```

### 2. æ—¥å¿—æŸ¥çœ‹æ¥å£

**ç›®çš„**: è®©å‰ç«¯èƒ½å¤ŸæŸ¥çœ‹åç«¯è¿è¡Œæ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•å’Œç›‘æ§ã€‚

#### åç«¯ä¿®æ”¹

1. **main.py** - æ—¥å¿—æ–‡ä»¶é…ç½®
   ```python
   LOG_FILE = "logs/love_advisor.log"
   logger.add(LOG_FILE, rotation="10 MB", retention="7 days")
   ```
   - æ—¥å¿—æ–‡ä»¶: `backend/logs/love_advisor.log`
   - æ»šåŠ¨ç­–ç•¥: 10MB è‡ªåŠ¨åˆ‡åˆ†
   - ä¿ç•™ç­–ç•¥: 7 å¤©

2. **main.py** - æ–°å¢æ¥å£ `/api/system/logs`
   ```python
   @app.get("/api/system/logs")
   async def get_system_logs(lines: int = 100):
       # è¿”å›æœ€å N è¡Œæ—¥å¿—
   ```

#### API ä½¿ç”¨ç¤ºä¾‹

```bash
# è·å–æœ€å 100 è¡Œæ—¥å¿—
curl http://127.0.0.1:8000/api/system/logs?lines=100

# è·å–æœ€å 20 è¡Œæ—¥å¿—
curl http://127.0.0.1:8000/api/system/logs?lines=20
```

**å‰ç«¯ä½¿ç”¨åœºæ™¯**:
- è®¾ç½®é¢æ¿ä¸­çš„"å¼€å‘è€…æ¨¡å¼"
- æ˜¾ç¤ºå®æ—¶æ—¥å¿—æµ
- é”™è¯¯è¯Šæ–­å·¥å…·

---

## ğŸ“Š æ—¥å¿—æ ¼å¼

æ‰€æœ‰æ—¥å¿—åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
- **æ—¶é—´æˆ³**: `2026-01-29 22:36:54`
- **çº§åˆ«**: INFO / SUCCESS / ERROR
- **æ¶ˆæ¯**: å¸¦ emoji çš„æè¿°æ€§ä¿¡æ¯

ç¤ºä¾‹æ—¥å¿—ï¼š
```
2026-01-29 22:36:54 | INFO | ğŸ² [Random] Styles: ['é«˜å†·', 'å…ƒæ°”', 'ä¸­äºŒ'] | History Depth: 2
2026-01-29 22:36:54 | INFO | âš¡ [Request] Input: ä½ ä¸ºä»€ä¹ˆä¸å›åº”æˆ‘ï¼Ÿ... | Context: 2 messages
2026-01-29 22:36:56 | SUCCESS | âœ… [LLM] Generation successful | Options: 3
```

---

## ğŸ§ª æµ‹è¯•

è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯åŠŸèƒ½ï¼š

```bash
cd backend
python test_memory.py
```

æµ‹è¯•å†…å®¹ï¼š
1. âœ… å¸¦å†å²ä¸Šä¸‹æ–‡çš„å¤šè½®å¯¹è¯
2. âœ… æ—¥å¿—æŸ¥çœ‹æ¥å£å“åº”
3. âœ… å†å²è®°å½•é•¿åº¦é™åˆ¶éªŒè¯ï¼ˆ>32æ¡åº”æ‹’ç»ï¼‰

---

## ğŸ“ å‰ç«¯é›†æˆæŒ‡å—

### 1. å‘é€è¯·æ±‚æ—¶æºå¸¦å†å²

```typescript
// store/useStore.ts
const sendMessage = async (userInput: string) => {
  const { history, memoryMax } = useStore.getState();
  
  // æˆªå–æœ€è¿‘çš„ N æ¡å†å²ï¼ˆmemoryMax = 8-32ï¼‰
  const recentHistory = history.slice(-memoryMax);
  
  const response = await fetch('http://localhost:8000/api/chat', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      user_input: userInput,
      history: recentHistory.map(msg => ({
        role: msg.role,
        content: msg.content
      }))
    })
  });
  
  return response.json();
};
```

### 2. æŸ¥çœ‹æ—¥å¿—

```typescript
// components/SettingsModal.tsx
const fetchLogs = async () => {
  const response = await fetch('http://localhost:8000/api/system/logs?lines=50');
  const logs = await response.text();
  setLogs(logs);
};
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥ï¼šTask 3 å‰ç«¯é‡æ„

å‡†å¤‡ä½¿ç”¨ Next.js å®ç°ï¼š
- âœ¨ ç°ä»£åŒ– UIï¼ˆå‚è€ƒ Gemini/ChatGPTï¼‰
- ğŸ¨ æƒ…æ„ŸåŒ–è§†è§‰åé¦ˆ
- âš™ï¸ è®¾ç½®é¢æ¿ï¼ˆè®°å¿†æ·±åº¦ 8-32ï¼‰
- ğŸ“Š å®æ—¶æ—¥å¿—æŸ¥çœ‹å™¨

---

**æœ€åæ›´æ–°**: 2026-01-29
**çŠ¶æ€**: Task 2 åç«¯å¢å¼º âœ… å®Œæˆ
